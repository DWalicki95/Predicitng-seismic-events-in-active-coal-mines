{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn import set_config\n",
        "from sklearn.compose import make_column_transformer"
      ],
      "metadata": {
        "id": "S51FKyBQuGIn"
      },
      "id": "S51FKyBQuGIn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "2Q3R_6SRtM4V"
      },
      "id": "2Q3R_6SRtM4V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('/content/gdrive/MyDrive/Data Science Pro/Projekt konﾌ…owy/input_data_train_X')\n",
        "y_train = pd.read_csv('/content/gdrive/MyDrive/Data Science Pro/Projekt konﾌ…owy/input_data_train_y')\n",
        "X_test = pd.read_csv('/content/gdrive/MyDrive/Data Science Pro/Projekt konﾌ…owy/input_data_test_X')\n",
        "y_test = pd.read_csv('/content/gdrive/MyDrive/Data Science Pro/Projekt konﾌ…owy/input_data_test_y')"
      ],
      "metadata": {
        "id": "OUb2DbYBuEfu"
      },
      "id": "OUb2DbYBuEfu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting strings into binary values\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "metadata": {
        "id": "ty9e66_iMCGp"
      },
      "id": "ty9e66_iMCGp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_col_names(first_ts_col, last_ts_col):\n",
        "  return list(X_train.iloc[:, first_ts_col: last_ts_col].columns)"
      ],
      "metadata": {
        "id": "wB9htYaY07Bo"
      },
      "id": "wB9htYaY07Bo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count_eX\n",
        "counts_e2 = ts_col_names(13, 37)\n",
        "counts_e3 = ts_col_names(37, 61)\n",
        "counts_e4 = ts_col_names(61, 85)\n",
        "counts_e5 = ts_col_names(85, 109)\n",
        "counts_e6plus = ts_col_names(109, 133)\n",
        "#sum_eX\n",
        "sum_e2 = ts_col_names(133, 157)\n",
        "sum_e3 = ts_col_names(157, 181)\n",
        "sum_e4 = ts_col_names(181, 205)\n",
        "sum_e5 = ts_col_names(205, 229)\n",
        "sum_e6plus = ts_col_names(229, 253)\n",
        "#number_of_rock_bursts\n",
        "num_rock_bursts = ts_col_names(277,301)\n",
        "#highest_bump_energy\n",
        "h_bump_energy = ts_col_names(325, 349)\n",
        "\n",
        "max_gactivities = ts_col_names(349, 373)\n",
        "max_genergies = ts_col_names(373, 397)\n",
        "avg_gactivities = ts_col_names(397, 421)\n",
        "avg_genergies = ts_col_names(421, 445)\n",
        "max_diff_gactivities = ts_col_names(445, 469)\n",
        "max_diff_genergies = ts_col_names(469, 493)\n",
        "avg_diff_gactivities = ts_col_names(493, 517)\n",
        "avg_diff_genergies = ts_col_names(517, 541)"
      ],
      "metadata": {
        "id": "-qCp7Llr08WW"
      },
      "id": "-qCp7Llr08WW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of time series columns that will be used in further calucaltions\n",
        "ts_to_agg = [max_gactivities, max_genergies, avg_gactivities, avg_genergies]\n",
        "ts_to_agg_diff = [\n",
        "    max_diff_gactivities, max_diff_genergies, \n",
        "    avg_diff_gactivities, avg_diff_genergies\n",
        "    ]\n",
        "ts_to_sum = [\n",
        "    counts_e2, counts_e3, counts_e4, counts_e5, counts_e6plus, \n",
        "    sum_e2, sum_e3, sum_e4, sum_e5, sum_e6plus, \n",
        "    num_rock_bursts, h_bump_energy\n",
        "    ]\n",
        "ts_to_agg_combined = ts_to_agg + ts_to_agg_diff\n",
        "\n",
        "flattened_ts_to_agg = [col for ts in ts_to_agg for col in ts]\n",
        "flattened_ts_to_agg_diff = [col for ts in ts_to_agg_diff for col in ts]\n",
        "flattened_ts_to_sum = [col for ts in ts_to_sum for col in ts]"
      ],
      "metadata": {
        "id": "0Q0PflXBpNHy"
      },
      "id": "0Q0PflXBpNHy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the non-required column\n",
        "X_train.drop('main_working_id', axis=1, inplace=True)\n",
        "X_test.drop('main_working_id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "8-DreOMN1ukE"
      },
      "id": "8-DreOMN1ukE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here is custom Transformer - it sums whole 24 hours time series\n",
        "class SumTimeSeries(BaseEstimator, TransformerMixin):\n",
        "  def __init__ (self, flattened_ts_to_sum, ts_to_sum):\n",
        "    self.flattened_ts_to_sum=flattened_ts_to_sum\n",
        "    self.ts_to_sum = ts_to_sum\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    X_agg = X.copy()\n",
        "    for ts in self.ts_to_sum:\n",
        "      X_agg['sum_'+ts[0][: -2]] = X_agg[ts].sum(axis=1)\n",
        "    return X_agg"
      ],
      "metadata": {
        "id": "rq6YkrPI19hJ"
      },
      "id": "rq6YkrPI19hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesStatistics(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, flattened_ts_to_agg, flattened_ts_to_agg_diff, ts_to_agg, ts_to_agg_diff, last_X_hours=5):\n",
        "        self.flattened_ts_to_agg = flattened_ts_to_agg\n",
        "        self.flattened_ts_to_agg_diff = flattened_ts_to_agg_diff\n",
        "        self.ts_to_agg = ts_to_agg\n",
        "        self.ts_to_agg_diff = ts_to_agg_diff\n",
        "        self.last_X_hours = last_X_hours\n",
        "        self.transformed_column_names = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def ts_compute_stats(self, X, ts, abs_, last_X_hours):\n",
        "        # 24 hours statistics:\n",
        "        X[f'avg_' + ts[0][:-2]] = X[ts].mean(axis=1)\n",
        "        X[f'std_' + ts[0][:-2]] = X[ts].std(axis=1)\n",
        "        X[f'max_' + ts[0][:-2]] = X[ts].max(axis=1)\n",
        "        if abs_:\n",
        "            X['abs_avg_' + ts[0][:-2]] = X[ts].abs().mean(axis=1)\n",
        "            X['max_abs_' + ts[0][:-2]] = X[ts].abs().max(axis=1)\n",
        "\n",
        "        # last X hours statistics:\n",
        "        X[f'avg_{last_X_hours}h_' + ts[0][:-2]] = X[ts[-last_X_hours:]].mean(axis=1)\n",
        "        X[f'std_{last_X_hours}h_' + ts[0][:-2]] = X[ts[-last_X_hours:]].std(axis=1)\n",
        "\n",
        "        slopes = []\n",
        "        for _, row in X.iterrows():\n",
        "          Y = row[ts[-last_X_hours:]].astype(np.float64)\n",
        "          X_data = np.arange(len(Y))\n",
        "          \n",
        "          # check if all values in Y are the same\n",
        "          if np.all(Y == Y[0]):\n",
        "              slope = 0\n",
        "          else:\n",
        "              slope = np.polyfit(X_data, Y, 1, rcond=1e-8)[0]\n",
        "        \n",
        "          slopes.append(slope)\n",
        "        X['slope_of_lr_' + ts[0][:-2]] = slopes\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        for ts_list in self.ts_to_agg:\n",
        "            ts = [col_name for col_name in X_copy.columns if any(col_name.startswith(ts_name) for ts_name in ts_list)]\n",
        "            print(f\"Processing ts_to_agg columns: {ts}\")\n",
        "            self.ts_compute_stats(X_copy, ts, False, self.last_X_hours)\n",
        "\n",
        "        for ts_list in self.ts_to_agg_diff:\n",
        "            ts = [col_name for col_name in X_copy.columns if any(col_name.startswith(ts_name) for ts_name in ts_list)]\n",
        "            print(f\"Processing ts_to_agg_diff columns: {ts}\")\n",
        "            self.ts_compute_stats(X_copy, ts, True, self.last_X_hours)\n",
        "\n",
        "        #column name update after time series aggregations\n",
        "        self.transformed_column_names = X_copy.columns\n",
        "\n",
        "        return X_copy"
      ],
      "metadata": {
        "id": "qfgWsYZ_-6VT"
      },
      "id": "qfgWsYZ_-6VT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cor_selector(X, y, num_feats: int):\n",
        "  '''\n",
        "Calculating Pearson correlation between each feature and prediction. Finding the \n",
        "most important features basing on correlation.\n",
        "  '''\n",
        "  cor_list = []\n",
        "  features = X.columns.tolist()\n",
        "  for feature in features:\n",
        "    cor = np.corrcoef(X[feature], y)[0, 1]\n",
        "    cor_list.append(cor)\n",
        "  #Nan -> 0\n",
        "  cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "  cor_feature = X.iloc[:, \n",
        "                       np.argsort(np.abs(cor_list))\n",
        "                       [-num_feats: ]\n",
        "                       ].columns.tolist()\n",
        "  #feature selection\n",
        "  cor_support = [True if i in cor_feature else False for i in features]\n",
        "  \n",
        "  return cor_support, cor_feature\n"
      ],
      "metadata": {
        "id": "mIME9F_WCg8Q"
      },
      "id": "mIME9F_WCg8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RFE_selector(X, y, num_feats):\n",
        "  'Finding the most important features basing on recursive feature elimination'\n",
        "\n",
        "  rfe_selector = RFE(\n",
        "      estimator=LogisticRegression(), n_features_to_select=num_feats, \n",
        "      step=10)\n",
        "  rfe_selector.fit(X, y)\n",
        "  rfe_support = rfe_selector.get_support()\n",
        "  rfe_feature = X.loc[:, rfe_support].columns.tolist()\n",
        "  \n",
        "  return rfe_support, rfe_feature"
      ],
      "metadata": {
        "id": "VnIMt5x_F77R"
      },
      "id": "VnIMt5x_F77R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Lasso_selector(X, y, num_feats):\n",
        "  '''\n",
        "  Finding the most important features basing on meta-transformer \n",
        "  that used alongside Logistic Regression estimator that assigns importance \n",
        "  to each feature.\n",
        "  '''\n",
        "\n",
        "  lr_selector = SelectFromModel(\n",
        "      LogisticRegression(penalty='l2'), max_features=num_feats)\n",
        "  lr_selector.fit(X, y)\n",
        "  lr_support = lr_selector.get_support()\n",
        "  lr_feature = X.loc[:, lr_support].columns.tolist()\n",
        "\n",
        "  return lr_support, lr_feature"
      ],
      "metadata": {
        "id": "RwyTFZbGF8gH"
      },
      "id": "RwyTFZbGF8gH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RanFor_selector(X, y, num_feats):\n",
        "  '''\n",
        "  Finding the most important features basing on meta-transformer \n",
        "  that used alongside Random Forest estimator that assigns importance \n",
        "  to each feature.\n",
        "  '''\n",
        "\n",
        "  rf_selector = SelectFromModel(\n",
        "      RandomForestClassifier(n_estimators=60), max_features=num_feats)\n",
        "  rf_selector.fit(X, y)\n",
        "  rf_support = rf_selector.get_support()\n",
        "  rf_feature = X.loc[:, rf_support].columns.tolist()\n",
        "\n",
        "  return rf_support, rf_feature"
      ],
      "metadata": {
        "id": "r7sUfrO2F-uI"
      },
      "id": "r7sUfrO2F-uI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LGBMC_optimizer(X, y, num_feats, selector=False):\n",
        "  '''\n",
        "  Finding best LGBMClassifier hyperparameters for SelectFromModel\n",
        "  feature selection\n",
        "  '''\n",
        "\n",
        "  lgbc = LGBMClassifier()\n",
        "\n",
        "  max_depth = [-1, 0, 1, 5, 20]\n",
        "  num_leaves = [1, 2, 16 ,32]\n",
        "  reg_lambda = [0, 1, 5, 10, 25, 100]\n",
        "  learning_rate = [0.01, 0.05, 0.1, 1]\n",
        "  min_gain_to_split = [0, 0.1, 1]\n",
        "  min_child_weight = [1e-3, 1e-1, 0, 10, 40]\n",
        "\n",
        "  params = {\n",
        "      'max_depth': max_depth,\n",
        "      'num_leaves': num_leaves,\n",
        "      'reg_lambda': reg_lambda,\n",
        "      'learning_rate': learning_rate,\n",
        "      'min_gain_to_split': min_gain_to_split,\n",
        "      'min_child_weight': min_child_weight,\n",
        "       }\n",
        "\n",
        "  kfold = StratifiedKFold(3, shuffle=True, random_state=42)\n",
        "  optimizer = RandomizedSearchCV(estimator=lgbc,\n",
        "                                 param_distributions=params,\n",
        "                                 scoring='roc_auc',\n",
        "                                 cv=kfold)\n",
        "  optimizer.fit(X, y)\n",
        "\n",
        "  return optimizer.best_params_, optimizer.best_estimator_\n"
      ],
      "metadata": {
        "id": "TioDF7-VGAg5"
      },
      "id": "TioDF7-VGAg5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LGBMC_selector(X, y, num_feats, optimization=False):\n",
        "  '''\n",
        "  Finding the most important features basing on meta-transformer \n",
        "  that used alongside LGBMClassifier that assigns importance \n",
        "  to each feature.\n",
        "  If optimization = False it is base LGBClassifier without optimizing\n",
        "  hyperparameters. Setting it to True runs LGBMC_optimizer function.\n",
        "  '''\n",
        "\n",
        "  if optimization:\n",
        "    best_params, lgbc = LGBMC_optimizer(X, y, num_feats, selector=True)\n",
        "  else:\n",
        "    lgbc = LGBMClassifier()\n",
        "  lgbc_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
        "  lgbc_selector.fit(X, y)\n",
        "  lgbc_support = lgbc_selector.get_support()\n",
        "  lgbc_feature = X.loc[:, lgbc_support].columns.tolist()\n",
        "\n",
        "  return lgbc_support, lgbc_feature"
      ],
      "metadata": {
        "id": "yq1t6brsGCQc"
      },
      "id": "yq1t6brsGCQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#third transformer designed for feature selection composed of Pearson correlation,\n",
        "#RFE and SelectFromModel (Logistic Regression and Random Forest)\n",
        "class FeatureSelectionTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, num_feats=50, optimization=False):\n",
        "    self.num_feats = num_feats\n",
        "    self.optimization = optimization\n",
        "\n",
        "  def fit(self, X, y):\n",
        "\n",
        "    cor_support, cor_feature = cor_selector(X, y, self.num_feats)\n",
        "    rfe_support, rfe_feature = RFE_selector(X, y, self.num_feats)\n",
        "    rf_support, rf_feature = RanFor_selector(X, y, self.num_feats)\n",
        "    lgbc_support, lgbc_feature = LGBMC_selector(X, y, self.num_feats)\n",
        "\n",
        "    feature_name = list(X.columns)\n",
        "    feature_selection_df = pd.DataFrame({\n",
        "        'Feature': feature_name,\n",
        "        'Pearson': cor_support,\n",
        "        'RFE': rfe_support,\n",
        "        'Random_forest': rf_support,\n",
        "        'LightGBM': lgbc_support\n",
        "        })\n",
        "\n",
        "    feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
        "    feature_selection_df = feature_selection_df.sort_values(\n",
        "        ['Total', 'Feature'],\n",
        "         ascending=False)\n",
        "    imp_features = feature_selection_df[\n",
        "        feature_selection_df['Total'] > 1\n",
        "        ]['Feature'].values\n",
        "    self.imp_features = imp_features\n",
        "\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    X_selected = X.copy()\n",
        "    X_selected = X[self.imp_features]\n",
        "\n",
        "    return X_selected"
      ],
      "metadata": {
        "id": "0OFOjyScGEY2"
      },
      "id": "0OFOjyScGEY2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LGBMC_optimizer(X, y, num_feats, selector=False):\n",
        "  '''\n",
        "  Finding best LGBMClassifier hyperparameters for SelectFromModel\n",
        "  feature selection\n",
        "  '''\n",
        "\n",
        "  lgbc = LGBMClassifier()\n",
        "\n",
        "  max_depth = [-1, 0, 1, 5, 20]\n",
        "  num_leaves = [1, 2, 16 ,32]\n",
        "  reg_lambda = [0, 1, 5, 10, 25, 100]\n",
        "  learning_rate = [0.01, 0.05, 0.1, 1]\n",
        "  min_gain_to_split = [0, 0.1, 1]\n",
        "  min_child_weight = [1e-3, 1e-1, 0, 10, 40]\n",
        "\n",
        "  params = {\n",
        "      'max_depth': max_depth,\n",
        "      'num_leaves': num_leaves,\n",
        "      'reg_lambda': reg_lambda,\n",
        "      'learning_rate': learning_rate,\n",
        "      'min_gain_to_split': min_gain_to_split,\n",
        "      'min_child_weight': min_child_weight,\n",
        "       }\n",
        "\n",
        "  kfold = StratifiedKFold(3, shuffle=True, random_state=42)\n",
        "  optimizer = RandomizedSearchCV(estimator=lgbc,\n",
        "                                 param_distributions=params,\n",
        "                                 scoring='roc_auc',\n",
        "                                 cv=kfold)\n",
        "  optimizer.fit(X, y)\n",
        "\n",
        "  return optimizer.best_params_, optimizer.best_estimator_\n"
      ],
      "metadata": {
        "id": "_lq1KfHe4-oq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_lq1KfHe4-oq"
    },
    {
      "cell_type": "code",
      "source": [
        "def LGBMC_selector(X, y, num_feats, optimization=False):\n",
        "  '''\n",
        "  Finding the most important features basing on meta-transformer \n",
        "  that used alongside LGBMClassifier that assigns importance \n",
        "  to each feature.\n",
        "  If optimization = False it is base LGBClassifier without optimizing\n",
        "  hyperparameters. Setting it to True runs LGBMC_optimizer function.\n",
        "  '''\n",
        "\n",
        "  if optimization:\n",
        "    best_params, lgbc = LGBMC_optimizer(X, y, num_feats, selector=True)\n",
        "  else:\n",
        "    lgbc = LGBMClassifier()\n",
        "  lgbc_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
        "  lgbc_selector.fit(X, y)\n",
        "  lgbc_support = lgbc_selector.get_support()\n",
        "  lgbc_feature = X.loc[:, lgbc_support].columns.tolist()\n",
        "\n",
        "  return lgbc_support, lgbc_feature"
      ],
      "metadata": {
        "id": "bigGxZa14-or"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bigGxZa14-or"
    },
    {
      "cell_type": "code",
      "source": [
        "class ArrayToDataFrame(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return pd.DataFrame(X, columns=self.column_names)"
      ],
      "metadata": {
        "id": "c0D2PFOm_bEf"
      },
      "id": "c0D2PFOm_bEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = ['latest_seismic_assessment', 'latest_seismoacoustic_assessment', \n",
        "                'latest_comprehensive_assessment', 'latest_hazards_assessment']\n",
        "\n",
        "#1st transformer - categorical variables encoding\n",
        "cat_trf = Pipeline(steps=[\n",
        "        ('cat_encode', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "#2nd transformer - scaler\n",
        "scaler_trf = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "wbMcSw5T2DtU"
      },
      "id": "wbMcSw5T2DtU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_ts_trf = SumTimeSeries(flattened_ts_to_sum, ts_to_sum)\n",
        "ts_stats_trf = TimeSeriesStatistics(flattened_ts_to_agg, flattened_ts_to_agg_diff, \n",
        "                                    ts_to_agg, ts_to_agg_diff, last_X_hours=5)\n",
        "\n",
        "X_train_transformed_sum_ts = sum_ts_trf.fit_transform(X_train)\n",
        "X_train_transformed_ts_stats = ts_stats_trf.fit_transform(X_train_transformed_sum_ts)\n",
        "\n",
        "num_features = [col for col in X_train_transformed_ts_stats.columns if col not in cat_features]"
      ],
      "metadata": {
        "id": "-xJZpQ4tWlTO"
      },
      "id": "-xJZpQ4tWlTO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing using all transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('ts_sum_trf', sum_ts_trf, flattened_ts_to_sum),\n",
        "        ('ts_stats_trf', ts_stats_trf, flattened_ts_to_agg + flattened_ts_to_agg_diff),\n",
        "        ('cat_enc_trf', cat_trf, cat_features),\n",
        "        ('scaler', scaler_trf, num_features)\n",
        "    ], remainder='passthrough')"
      ],
      "metadata": {
        "id": "Zh2Yw9sIL_4l"
      },
      "id": "Zh2Yw9sIL_4l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class balance\n",
        "sm = SMOTE(sampling_strategy='auto', k_neighbors=8, random_state=42)"
      ],
      "metadata": {
        "id": "cMCan4zM-8ej"
      },
      "id": "cMCan4zM-8ej",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector_trf = ColumnTransformer([\n",
        "        ('selector', FeatureSelectionTransformer(optimization=True), slice(None))   \n",
        "])"
      ],
      "metadata": {
        "id": "_DJh6iQEh7Wg"
      },
      "id": "_DJh6iQEh7Wg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model LigtGBM\n",
        "model = LGBMClassifier(\n",
        "    num_leaves=1500, num_iterations=80, \n",
        "    min_data_in_leaf=750, max_depth=22,\n",
        "    learning_rate=0.03, lambda_l2=10,\n",
        "    lambda_l1=1, boosting_type='gbdt'\n",
        ")"
      ],
      "metadata": {
        "id": "MOQ5-vVyRGPE"
      },
      "id": "MOQ5-vVyRGPE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('smote', sm),\n",
        "    ('to_df', ArrayToDataFrame(X_train_transformed_ts_stats.columns)),\n",
        "    ('selector', selector_trf),\n",
        "    ('model', model)\n",
        "])"
      ],
      "metadata": {
        "id": "7iOFNj_YVf2c"
      },
      "id": "7iOFNj_YVf2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wr8SDg1CZpJ0"
      },
      "id": "wr8SDg1CZpJ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_config(display='diagram')"
      ],
      "metadata": {
        "id": "28uu-9tqXXv4"
      },
      "id": "28uu-9tqXXv4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}